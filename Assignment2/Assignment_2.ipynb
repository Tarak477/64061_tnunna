{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oAgWzCx1yPaW"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBDdSA3JyPlp"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0tHnJBTlyQDN"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8rOA-cmeyQST"
      },
      "outputs": [],
      "source": [
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI76YijYyQuL"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r0bMwmwayfdM"
      },
      "outputs": [],
      "source": [
        "!unzip -qq dogs-vs-cats.zip\n",
        "!unzip -qq train.zip\n",
        "!unzip -qq test1.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfwkzjISRSEm"
      },
      "source": [
        "### **Question-1** \n",
        "Consider the Cats & Dogs example. Start initially with a training sample of 1000, a validation sample of 500, and a test sample of 500 (like in the text). Use any technique to reduce overfitting and improve performance in developing a network that you train from scratch. What performance did you achieve?  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDcSbR_0D_iO"
      },
      "source": [
        "Dividing the Dataset into Train, Validation and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8BLel8VKQu05"
      },
      "outputs": [],
      "source": [
        "import os, shutil, pathlib\n",
        "shutil.rmtree(\"./cats_vs_dogs_small\", ignore_errors=True)\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyhMgQNgRU56"
      },
      "source": [
        "Preprocessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR36_FGmQzro"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "random_numbers = np.random.normal(size=(1000, 16))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(random_numbers)\n",
        "\n",
        "for i, element in enumerate(dataset):\n",
        "    print(\"Dataset shape\",i,\":\",element.shape)\n",
        "    if i >= 2:\n",
        "        break\n",
        "\n",
        "batched_dataset = dataset.batch(32)\n",
        "for i, element in enumerate(batched_dataset):\n",
        "    print(\"Batch shape \",i,\" :\",element.shape)\n",
        "    if i >= 2:\n",
        "        break\n",
        "\n",
        "reshaped_dataset = dataset.map(lambda x: tf.reshape(x, (4, 4)))\n",
        "print(\"Reshaped datasets\")\n",
        "for i, element in enumerate(reshaped_dataset):\n",
        "    print(\"Dataset shape\",i,\":\",element.shape)\n",
        "    if i >= 2:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-7rjmX8RCC3"
      },
      "outputs": [],
      "source": [
        "for data_batch, labels_batch in train_dataset:\n",
        "    print(\"data batch shape:\", data_batch.shape)\n",
        "    print(\"labels batch shape:\", labels_batch.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQlcSWD_RYWX"
      },
      "source": [
        "# Training Convent from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx2Td9ZLeX_L"
      },
      "source": [
        "Unregularised model with small sample size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF3Na2yWRIRg"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aKRU5MQrRMkc"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E7vjmmDRaj8"
      },
      "source": [
        "Model fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy6yKcJMRbJp"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAzGQf6OelIs"
      },
      "source": [
        "1. Plotting Graph for Training and Validation accuracy\n",
        "2. Plotting Graph for Training and Validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej57mI_eRiPg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNd3kdVFfXc9"
      },
      "source": [
        "Evaluating the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lakdQ_YePjlx"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "i7Qis7ppP0XN"
      },
      "outputs": [],
      "source": [
        "loss1=[]\n",
        "accurcy=[]\n",
        "modelname=['model']\n",
        "loss1.append(np.mean(test_loss))\n",
        "accurcy.append(np.mean(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5tdY51wP6fc"
      },
      "outputs": [],
      "source": [
        "len(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqSQrtP6i7BQ"
      },
      "source": [
        "### Trying for the best Accuracy by adding different % of droput rate and data augmentation to our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sC2zORoAQ34U"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtc-KZY3jC0N"
      },
      "source": [
        "Displaying some randomly augmented training images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7G2oiWdRAsk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLpHdImFjF9n"
      },
      "source": [
        "# Convent using dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVzVKzRXRSZE"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)    # Layer 1\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.25)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)    # Layer 2\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.20)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)   # Layer 3\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.35)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)   # Layer 4\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)   # Layer 5\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_1 = keras.Model(inputs=inputs, outputs=outputs)\n",
        "model_1.summary()\n",
        "\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-sMhdYTjR69"
      },
      "source": [
        "Model Fitting using Regularised Convent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo4W8Qn9RFQ9"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_model_1.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history1 = model_1.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sxKdIHqMqfr"
      },
      "source": [
        "1. Plotting Graph for Training and Validation accuracy\n",
        "2. Plotting Graph for Training and Validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBlegUJRMlp-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy = history1.history[\"accuracy\"]\n",
        "val_accuracy = history1.history[\"val_accuracy\"]\n",
        "loss = history1.history[\"loss\"]\n",
        "val_loss = history1.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDQcphoHM-sr"
      },
      "source": [
        "Evaluating the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbI1ZWGyM_Su"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(\"convnet_from_scratch_model_1.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "n-dL_UqdNFy9"
      },
      "outputs": [],
      "source": [
        "modelname=['model','model_1']\n",
        "loss1.append(np.mean(test_loss))\n",
        "accurcy.append(np.mean(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYFrmvRONJ0d"
      },
      "outputs": [],
      "source": [
        "loss1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XnVXH0WQ8kl"
      },
      "source": [
        "###Question 2\n",
        "Increase your training sample size. You may pick any amount. Keep the validation and test \n",
        "samples the same as above. Optimize your network (again training from scratch). What \n",
        "performance did you achieve?  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JIFqGVNbQ9EK"
      },
      "outputs": [],
      "source": [
        "import os, shutil, pathlib\n",
        "shutil.rmtree(\"./cats_vs_dogs_small\", ignore_errors=True)\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=2000)\n",
        "make_subset(\"validation\", start_index=2000, end_index=2500)\n",
        "make_subset(\"test\", start_index=2500, end_index=3000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgQaciqOSQyA"
      },
      "source": [
        "Managing the file direcotry; Splitting the file system into train(1000), test(500) and validation(500) folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu_thEcFRTxb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "random_numbers = np.random.normal(size=(1000, 16))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(random_numbers)\n",
        "\n",
        "for i, element in enumerate(dataset):\n",
        "    print(\"Dataset shape\",i,\":\",element.shape)\n",
        "    if i >= 2:\n",
        "        break\n",
        "\n",
        "batched_dataset = dataset.batch(32)\n",
        "for i, element in enumerate(batched_dataset):\n",
        "    print(\"Batch shape \",i,\" :\",element.shape)\n",
        "    if i >= 2:\n",
        "        break\n",
        "\n",
        "reshaped_dataset = dataset.map(lambda x: tf.reshape(x, (4, 4)))\n",
        "print(\"Reshaped datasets\")\n",
        "for i, element in enumerate(reshaped_dataset):\n",
        "    print(\"Dataset shape\",i,\":\",element.shape)\n",
        "    if i >= 2:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7xtWlZmSvbg"
      },
      "source": [
        "Displaying the shapes of the data and labels yielded by the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRiUAlYrSwvJ"
      },
      "outputs": [],
      "source": [
        "for data_batch, labels_batch in train_dataset:\n",
        "    print(\"data batch shape:\", data_batch.shape)\n",
        "    print(\"labels batch shape:\", labels_batch.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3BtmxR2S3MK"
      },
      "source": [
        "Fitting model to new dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3HCAYCqS7eK"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_3.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history3 = model_1.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0JJniXtS6yj"
      },
      "source": [
        "1. Plotting Graph for Training and Validation accuracy\n",
        "2. Plotting Graph for Training and Validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_TNsz_OTJzf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy = history3.history[\"accuracy\"]\n",
        "val_accuracy = history3.history[\"val_accuracy\"]\n",
        "loss = history3.history[\"loss\"]\n",
        "val_loss = history3.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6NSDnk9TRfp"
      },
      "source": [
        "Evaluating the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBaARL_rTWEz"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(\"convnet_from_scratch_3.keras\")\n",
        "test_loss, test_acc = model_1.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gegw2fTiTc7e"
      },
      "outputs": [],
      "source": [
        "loss1.append(np.mean(test_loss))\n",
        "accurcy.append(np.mean(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NITVmsITcwr"
      },
      "outputs": [],
      "source": [
        "loss1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWAn0q0lTiYJ"
      },
      "source": [
        "We can observe that the accuracy of the new dataset is higher than that of the prior one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlLPxnzgTzu0"
      },
      "source": [
        "###Question 3\n",
        "Now change your training sample so that you achieve better performance than those from Steps \n",
        "1 and 2. This sample size may be larger, or smaller than those in the previous steps. The \n",
        "objective is to find the ideal training sample size to get best prediction results.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORyOB28xUL8j"
      },
      "source": [
        "Here I will be taking the mean amount of training set as of question 1 and 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dhe3YlHGTwF4"
      },
      "outputs": [],
      "source": [
        "import os, shutil, pathlib\n",
        "shutil.rmtree(\"./cats_vs_dogs_small\", ignore_errors=True)\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1500)\n",
        "make_subset(\"validation\", start_index=1500, end_index=1750)\n",
        "make_subset(\"test\", start_index=1750, end_index=2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLaEoX21UxUe"
      },
      "source": [
        "PreProcessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-oS27khU8Bg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "random_numbers = np.random.normal(size=(1000, 16))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(random_numbers)\n",
        "\n",
        "for i, element in enumerate(dataset):\n",
        "    print(\"Dataset shape\",i,\":\",element.shape)\n",
        "    if i >= 2:\n",
        "        break\n",
        "\n",
        "batched_dataset = dataset.batch(32)\n",
        "for i, element in enumerate(batched_dataset):\n",
        "    print(\"Batch shape \",i,\" :\",element.shape)\n",
        "    if i >= 2:\n",
        "        break\n",
        "\n",
        "reshaped_dataset = dataset.map(lambda x: tf.reshape(x, (4, 4)))\n",
        "print(\"Reshaped datasets\")\n",
        "for i, element in enumerate(reshaped_dataset):\n",
        "    print(\"Dataset shape\",i,\":\",element.shape)\n",
        "    if i >= 2:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIOZm6EFVDPq"
      },
      "source": [
        "Displaying the shapes of the data and labels yielded by the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cI--gK_fVEJO"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1a16zYXVL2I"
      },
      "source": [
        "Fitting Model to new Datset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK1W7e47VNAN"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_4.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history4 = model_1.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajs7-TojVXyz"
      },
      "source": [
        "1. Plotting Graph for Training and Validation accuracy\n",
        "2. Plotting Graph for Training and Validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yorD0zDdVicy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "accuracy = history4.history[\"accuracy\"]\n",
        "val_accuracy = history4.history[\"val_accuracy\"]\n",
        "loss = history4.history[\"loss\"]\n",
        "val_loss = history4.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nZhWBXdV1tj"
      },
      "source": [
        "Evaluating the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4GnrMaGVnDF"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(\"convnet_from_scratch_4.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RryimCn8V4yf"
      },
      "outputs": [],
      "source": [
        "loss1.append(np.mean(test_loss))\n",
        "accurcy.append(np.mean(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xosu9JupWFEu"
      },
      "source": [
        "### Question 4\n",
        "Repeat Steps 1-3, but now using a pretrained network. The sample sizes you use in Steps 2 and 3 \n",
        "for the pretrained network may be the same or different from those using the network where \n",
        "you trained from scratch. Again, use any and all optimization techniques to get best \n",
        "performance. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X23nCC_WNhS"
      },
      "outputs": [],
      "source": [
        "import os, shutil, pathlib\n",
        "shutil.rmtree(\"./cats_vs_dogs_small\", ignore_errors=True)\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP2xfDbvWYrZ"
      },
      "source": [
        "Managing the file direcotry; Splitting the file system into train(1000), test(500) and validation(500) folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPNCEL6DWZEa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfoO6fUCWj-t"
      },
      "outputs": [],
      "source": [
        "conv_base = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKvdcCQQWnW1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_features_and_labels(dataset):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    for images, labels in dataset:\n",
        "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
        "        features = conv_base.predict(preprocessed_images)\n",
        "        all_features.append(features)\n",
        "        all_labels.append(labels)\n",
        "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
        "\n",
        "train_features, train_labels =  get_features_and_labels(train_dataset)\n",
        "val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
        "test_features, test_labels =  get_features_and_labels(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYnsyqZBW9n_"
      },
      "source": [
        "Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHovWudKWrhH"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extraction.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "history_3 = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZhmTt7TW_96"
      },
      "source": [
        "1. Plotting Graph for Training and Validation accuracy\n",
        "2. Plotting Graph for Training and Validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gt7BU3zWu8r"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history_3.history[\"accuracy\"]\n",
        "val_acc = history_3.history[\"val_accuracy\"]\n",
        "loss = history_3.history[\"loss\"]\n",
        "val_loss = history_3.history[\"val_loss\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOVv2F02XYii"
      },
      "source": [
        "\n",
        "Evaluating the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbnazB9mXZm4"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(\"feature_extraction_with_data_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpOg12d3Xny1"
      },
      "outputs": [],
      "source": [
        "loss1.append(np.mean(test_loss))\n",
        "accurcy.append(np.mean(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-Vw9FzClMMg"
      },
      "source": [
        "Managing the file direcotry; Splitting the file system into train(2000), test(500) and validation(500) folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKPaT7V8Xti4"
      },
      "outputs": [],
      "source": [
        "import os, shutil, pathlib\n",
        "shutil.rmtree(\"./cats_vs_dogs_small\", ignore_errors=True)\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=2000)\n",
        "make_subset(\"validation\", start_index=2000, end_index=2500)\n",
        "make_subset(\"test\", start_index=2500, end_index=3000)\n",
        "\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VODHwdga_kHW"
      },
      "outputs": [],
      "source": [
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBsgwfVPkh9S"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = True\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"before freezing the conv base:\", len(conv_base.trainable_weights))\n",
        "conv_base.trainable = False\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"before freezing the conv base:\", len(conv_base.trainable_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzV3Wt_tkjCX"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVd23cALlCjP"
      },
      "source": [
        "Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHQhdaJaknCt"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"feature_extraction_with_data_augmentation.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history_final_3 = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR9jO0X7kzu4"
      },
      "source": [
        "1. Plotting Graph for Training and Validation accuracy\n",
        "2. Plotting Graph for Training and Validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDWzOkdwkrcJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history_final_3.history[\"accuracy\"]\n",
        "val_acc = history_final_3.history[\"val_accuracy\"]\n",
        "loss = history_final_3.history[\"loss\"]\n",
        "val_loss = history_final_3.history[\"val_loss\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rpR9ddnkvXO"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"feature_extraction_with_data_augmentation.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnzvKMC0laCL"
      },
      "outputs": [],
      "source": [
        "loss1\n",
        "accurcy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecTnFemUlqxd"
      },
      "outputs": [],
      "source": [
        "loss1.append(np.mean(test_loss))\n",
        "accurcy.append(np.mean(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zp_7tBKlrhf"
      },
      "source": [
        "In this case, I'll use the mean number of training set from questions 1 and 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PupzRKxll7jP"
      },
      "source": [
        "Managing the file direcotry; Splitting the file system into train(1500), test(250) and validation(250) folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L-OmC_9l0lU"
      },
      "outputs": [],
      "source": [
        "import os, shutil, pathlib\n",
        "shutil.rmtree(\"./cats_vs_dogs_small\", ignore_errors=True)\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1500)\n",
        "make_subset(\"validation\", start_index=1500, end_index=1750)\n",
        "make_subset(\"test\", start_index=1750, end_index=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbpzh8AHmGBE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTHJjsRimMkb"
      },
      "outputs": [],
      "source": [
        "conv_base.trainable = True\n",
        "for layer in conv_base.layers[:-4]:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6f56FEmmOAv"
      },
      "source": [
        "Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JY92pvb_mNkp"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
        "              metrics=[\"accuracy\"])   \n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"fine_tuning.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history_final_RM_3 = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=30,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JylrI7pImTnn"
      },
      "source": [
        "1. Plotting Graph for Training and Validation accuracy\n",
        "2. Plotting Graph for Training and Validation loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca0ihq9xmbXc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history_final_RM_3.history[\"accuracy\"]\n",
        "val_acc = history_final_RM_3.history[\"val_accuracy\"]\n",
        "loss = history_final_RM_3.history[\"loss\"]\n",
        "val_loss = history_final_RM_3.history[\"val_loss\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86pXO1jDmewk"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"fine_tuning.keras\")\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_a6VEngmieh"
      },
      "outputs": [],
      "source": [
        "loss1.append(np.mean(test_loss))\n",
        "accurcy.append(np.mean(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ofc9TktNmlLb"
      },
      "outputs": [],
      "source": [
        "print(loss1,'\\n',accurcy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVNdOue1moQF"
      },
      "outputs": [],
      "source": [
        "labels=['convnet_from_scratch','convnet_from_scratch_model_1','convnet_from_scratch_3','convnet_from_scratch_4','pretrained_feature_extraction','pretrained_feature_extraction_with_data_augmentation','pretrained_fine_tuning']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7mWoR_-nSnS"
      },
      "outputs": [],
      "source": [
        "All_Loss= np.array([0.6263572573661804,\n",
        " 0.594975471496582,\n",
        " 2.1392126083374023,\n",
        " 0.010953199118375778,\n",
        " 0.010953199118375778,\n",
        " 1.221186637878418,\n",
        " 0.035336028784513474])*100\n",
        "All_Loss\n",
        "All_Accuracy= np.array([0.675000011920929,\n",
        " 0.6819999814033508,\n",
        " 0.734000027179718,\n",
        " 0.9959999918937683,\n",
        " 0.9959999918937683,\n",
        " 0.968999981880188,\n",
        " 0.9940000176429749])*100\n",
        "All_Accuracy\n",
        "plt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1AhJyUInk_A"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,7.5))\n",
        "ax.scatter(All_Loss,All_Accuracy,c = np.random.rand(len(All_Accuracy)),s = np.sqrt(30 * All_Accuracy**2))\n",
        "for i, txt in enumerate(labels):\n",
        "    ax.annotate(txt, (All_Loss[i],All_Accuracy[i] ))\n",
        "plt.title(\"Final Summary for Accuracy and Loss\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m_-y3yCnsRL"
      },
      "source": [
        "#Summary\n",
        "As we could see in the Above plot, we could conclude that:\n",
        "\n",
        "Train Set: Because we used a small sample set for training, the model was unable to extract the characteristics of the data, and so the performance was poor.\n",
        "\n",
        "Training Techniques – Similarly, the performance of the pretrained layer appears to be slightly better than that of the model created from scratch. However, the loss for the Pretrained network is significantly little higher.\n",
        "\n",
        "Looking at the Loss and Accuracy, we can conclude that the best model created for the cat-vs-dogs dataset is a pretrained model on VGG16 with a training sample of 1500, where we acquired an accuracy of ~99 percent and a loss of roughly ~0.5.\n",
        "\n",
        "However, this may not be true for all types of image processing, and hypertuning is always important. We can always develop a better model by using hypertuning techniques and implementing procedures under the correct conditions."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment-2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}